{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import csv\n",
    "from tweepy import Cursor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = #put your key\n",
    "consumer_secret = #put your key\n",
    "access_token = #put your key\n",
    "access_token_secret = #put your key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create authentication for accessing Twitter\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "#initialize Tweepy API\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Scraping tweets by user-screen-name </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the twitter handle of the person whose tweets you want to download:- brunoaziza\n"
     ]
    }
   ],
   "source": [
    "screen_name = input(\"Enter the twitter handle of the person whose tweets you want to download:- \")\n",
    "\n",
    "\n",
    "# We will get the tweets with multiple requests of 200 tweets each\n",
    "new_tweets = api.user_timeline(screen_name=screen_name, count=200, tweet_mode='extended', lang = 'en')\n",
    "\n",
    "# initialization of a list to hold all Tweets\n",
    "all_the_tweets = []\n",
    "\n",
    "# saving the most recent tweets\n",
    "all_the_tweets.extend(new_tweets)\n",
    "\n",
    "# save id of 1 less than the oldest tweet\n",
    "oldest_tweet = all_the_tweets[-1].id - 1\n",
    "\n",
    "# grabbing tweets till none are left\n",
    "\n",
    "while len(new_tweets) > 0 and (time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(all_the_tweets[-1]._json['created_at'],'%a %b %d %H:%M:%S +0000 %Y')) > (datetime.datetime.today() -datetime.timedelta(days=7)).strftime('%Y-%m-%d %H:%M:%S')):\n",
    "\n",
    "    # The max_id param will be used subsequently to prevent duplicates\n",
    "    new_tweets = api.user_timeline(screen_name=screen_name, count=200, max_id=oldest_tweet, tweet_mode='extended', lang = 'en')\n",
    "\n",
    "    # save most recent tweets\n",
    "    all_the_tweets.extend(new_tweets)\n",
    "\n",
    "    # id is updated to oldest tweet - 1 to keep track\n",
    "    oldest_tweet = all_the_tweets[-1].id - 1\n",
    "    print ('...%s tweets have been downloaded so far' % len(all_the_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the tweets into a 2D array that will be used to populate the csv\n",
    "outtweets = [[tweet.id_str, tweet.user.screen_name, tweet.created_at,tweet.retweeted, tweet.retweet_count, \n",
    "              tweet.favorited, tweet.favorite_count, tweet.in_reply_to_screen_name, tweet.in_reply_to_user_id_str, \n",
    "              tweet.truncated, tweet.full_text, ''] for tweet in all_the_tweets \n",
    "             if tweet.lang=='en' and 'retweeted_status' not in tweet._json and 'quoted_status' not in tweet._json]\n",
    "\n",
    "\n",
    "retweeted_outtweets = [[tweet.id_str, tweet.user.screen_name, tweet.created_at,tweet.retweeted, tweet.retweet_count, \n",
    "              tweet.favorited, tweet.favorite_count, tweet.in_reply_to_screen_name, tweet.in_reply_to_user_id_str, \n",
    "              tweet.truncated, tweet.retweeted_status.full_text, ''] for tweet in all_the_tweets \n",
    "                       if tweet.lang=='en' and 'retweeted_status' in tweet._json and 'quoted_status' not in tweet._json]\n",
    "\n",
    "quoted_outtweets = [[tweet.id_str, tweet.user.screen_name, tweet.created_at,tweet.retweeted, tweet.retweet_count, \n",
    "              tweet.favorited, tweet.favorite_count, tweet.in_reply_to_screen_name, tweet.in_reply_to_user_id_str, \n",
    "              tweet.truncated, tweet.full_text, tweet.quoted_status.full_text] for tweet in all_the_tweets \n",
    "                    if tweet.lang=='en' and 'retweeted_status' not in tweet._json and 'quoted_status' in tweet._json]\n",
    "\n",
    "# writing to the csv file\n",
    "pd.DataFrame(outtweets+retweeted_outtweets+quoted_outtweets,columns=(['id', 'screen_name', 'created_at', 'retweeted',\n",
    "                                 'retweet_count', 'favorited', 'favorite_count',\n",
    "                                 'replyToSN', 'replyToUID','truncated', 'text', 'quoted_text'])).sort_values(by =['created_at'], ascending=False).to_csv(screen_name + '_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Scraping tweets by keywords </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...200 tweets have been downloaded so far\n",
      "...300 tweets have been downloaded so far\n",
      "...400 tweets have been downloaded so far\n",
      "...499 tweets have been downloaded so far\n",
      "...571 tweets have been downloaded so far\n",
      "...571 tweets have been downloaded so far\n"
     ]
    }
   ],
   "source": [
    "key_word = 'oracle analytics'\n",
    "\n",
    "# initialization of a list to hold all Tweets\n",
    "all_the_tweets = []\n",
    "\n",
    "\n",
    "# We will get the tweets with multiple requests of 200 tweets each\n",
    "new_tweets = api.search(q= key_word, count=200, tweet_mode='extended', lang = 'en')\n",
    "\n",
    "\n",
    "# saving the most recent tweets\n",
    "all_the_tweets.extend(new_tweets)\n",
    "\n",
    "# save id of 1 less than the oldest tweet\n",
    "oldest_tweet = all_the_tweets[-1].id - 1\n",
    "\n",
    "# grabbing tweets till none are left\n",
    "\n",
    "while len(new_tweets) > 0:\n",
    "\n",
    "    # The max_id param will be used subsequently to prevent duplicates\n",
    "    new_tweets = api.search(q= key_words, count=200, max_id=oldest_tweet, tweet_mode='extended', lang = 'en')\n",
    "\n",
    "    # save most recent tweets\n",
    "    all_the_tweets.extend(new_tweets)\n",
    "\n",
    "    # id is updated to oldest tweet - 1 to keep track\n",
    "    oldest_tweet = all_the_tweets[-1].id - 1\n",
    "    print ('...%s tweets have been downloaded so far' % len(all_the_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...770 tweets have been downloaded so far\n",
      "...868 tweets have been downloaded so far\n",
      "...899 tweets have been downloaded so far\n",
      "...899 tweets have been downloaded so far\n"
     ]
    }
   ],
   "source": [
    "key_word = 'oracleanalytics'\n",
    "\n",
    "\n",
    "# We will get the tweets with multiple requests of 200 tweets each\n",
    "new_tweets = api.search(q= key_word, count=200, tweet_mode='extended', lang = 'en')\n",
    "\n",
    "\n",
    "# saving the most recent tweets\n",
    "all_the_tweets.extend(new_tweets)\n",
    "\n",
    "# save id of 1 less than the oldest tweet\n",
    "oldest_tweet = all_the_tweets[-1].id - 1\n",
    "\n",
    "# grabbing tweets till none are left\n",
    "\n",
    "while len(new_tweets) > 0:\n",
    "\n",
    "    # The max_id param will be used subsequently to prevent duplicates\n",
    "    new_tweets = api.search(q= key_words, count=200, max_id=oldest_tweet, tweet_mode='extended', lang = 'en')\n",
    "\n",
    "    # save most recent tweets\n",
    "    all_the_tweets.extend(new_tweets)\n",
    "\n",
    "    # id is updated to oldest tweet - 1 to keep track\n",
    "    oldest_tweet = all_the_tweets[-1].id - 1\n",
    "    print ('...%s tweets have been downloaded so far' % len(all_the_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1099 tweets have been downloaded so far\n",
      "...1198 tweets have been downloaded so far\n",
      "...1263 tweets have been downloaded so far\n",
      "...1263 tweets have been downloaded so far\n"
     ]
    }
   ],
   "source": [
    "key_word = 'ukoug'\n",
    "\n",
    "\n",
    "# We will get the tweets with multiple requests of 200 tweets each\n",
    "new_tweets = api.search(q= key_word, count=200, tweet_mode='extended', lang = 'en')\n",
    "\n",
    "\n",
    "# saving the most recent tweets\n",
    "all_the_tweets.extend(new_tweets)\n",
    "\n",
    "# save id of 1 less than the oldest tweet\n",
    "oldest_tweet = all_the_tweets[-1].id - 1\n",
    "\n",
    "# grabbing tweets till none are left\n",
    "\n",
    "while len(new_tweets) > 0:\n",
    "\n",
    "    # The max_id param will be used subsequently to prevent duplicates\n",
    "    new_tweets = api.search(q= key_words, count=200, max_id=oldest_tweet, tweet_mode='extended', lang = 'en')\n",
    "\n",
    "    # save most recent tweets\n",
    "    all_the_tweets.extend(new_tweets)\n",
    "\n",
    "    # id is updated to oldest tweet - 1 to keep track\n",
    "    oldest_tweet = all_the_tweets[-1].id - 1\n",
    "    print ('...%s tweets have been downloaded so far' % len(all_the_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Saving all the tweets to csv file </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the tweets into a 2D array that will be used to populate the csv\n",
    "outtweets = [[tweet.id_str, tweet.user.screen_name, tweet.created_at,tweet.retweeted, tweet.retweet_count, \n",
    "              tweet.favorited, tweet.favorite_count, tweet.in_reply_to_screen_name, tweet.in_reply_to_user_id_str, \n",
    "              tweet.truncated, tweet.full_text, ''] for tweet in all_the_tweets \n",
    "             if tweet.lang=='en' and 'retweeted_status' not in tweet._json and 'quoted_status' not in tweet._json]\n",
    "\n",
    "\n",
    "retweeted_outtweets = [[tweet.id_str, tweet.user.screen_name, tweet.created_at,tweet.retweeted, tweet.retweet_count, \n",
    "              tweet.favorited, tweet.favorite_count, tweet.in_reply_to_screen_name, tweet.in_reply_to_user_id_str, \n",
    "              tweet.truncated, tweet.retweeted_status.full_text, ''] for tweet in all_the_tweets \n",
    "                       if tweet.lang=='en' and 'retweeted_status' in tweet._json and 'quoted_status' not in tweet._json]\n",
    "\n",
    "quoted_outtweets = [[tweet.id_str, tweet.user.screen_name, tweet.created_at,tweet.retweeted, tweet.retweet_count, \n",
    "              tweet.favorited, tweet.favorite_count, tweet.in_reply_to_screen_name, tweet.in_reply_to_user_id_str, \n",
    "              tweet.truncated, tweet.full_text, tweet.quoted_status.full_text] for tweet in all_the_tweets \n",
    "                    if tweet.lang=='en' and 'retweeted_status' not in tweet._json and 'quoted_status' in tweet._json]\n",
    "\n",
    "# writing to the csv file\n",
    "pd.DataFrame(outtweets+retweeted_outtweets+quoted_outtweets,columns=(['id', 'screen_name', 'created_at', 'retweeted',\n",
    "                                 'retweet_count', 'favorited', 'favorite_count',\n",
    "                                 'replyToSN', 'replyToUID','truncated', 'text', 'quoted_text'])).sort_values(by =['created_at'], ascending=False).to_csv(key_word + '_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> For fetching only the retweeted ones </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retweeted_outtweets = [[tweet.id_str, tweet.user.screen_name, tweet.created_at,tweet.retweeted, tweet.retweet_count, \n",
    "              tweet.favorited, tweet.favorite_count, tweet.in_reply_to_screen_name, tweet.in_reply_to_user_id_str, \n",
    "              tweet.truncated, tweet.retweeted_status.full_text, tweet.retweeted_status.user.screen_name, tweet.retweeted_status.user.description] for tweet in all_the_tweets \n",
    "                       if tweet.lang=='en' and 'retweeted_status' in tweet._json and 'quoted_status' not in tweet._json]\n",
    "\n",
    "# writing to the csv file\n",
    "pd.DataFrame(retweeted_outtweets,columns=(['id', 'screen_name', 'created_at', 'retweeted',\n",
    "                                 'retweet_count', 'favorited', 'favorite_count',\n",
    "                                 'replyToSN', 'replyToUID','truncated', 'text', 'retweeted_status-user-screen_name', 'retweeted_status-user-description' ])).sort_values(by =['created_at'], ascending=False).to_csv(key_word +'_tweets_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
